{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1546eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1daf9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Database Connection Details ---\n",
    "\n",
    "DB_USER = \"root\"\n",
    "DB_PASS = \"YourPassword\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"3306\"\n",
    "DB_NAME = \"zomato_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe9bee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the database engine\n",
    "\n",
    "engine = create_engine(f\"mysql+pymysql://{DB_USER}:{DB_PASS}@{DB_HOST}/{DB_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bdf1a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading raw data from CSV...\n",
      "üßπ Cleaning and preparing data...\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Load the Raw Data ---\n",
    "\n",
    "file_path = \"C:/Users/vaibh/Desktop/DA Project/ZomatoSQL/zomato.csv\"\n",
    "\n",
    "print(\"üì• Loading raw data from CSV...\")\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: The file was not found at '{file_path}'. Please update the file_path variable.\")\n",
    "    exit()\n",
    "\n",
    "print(\"üßπ Cleaning and preparing data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6245beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Data Cleaning and Preprocessing ---\n",
    "\n",
    "# Clean column names\n",
    "df.columns = [col.lower().replace(' ', '_') for col in df.columns]\n",
    "df.rename(columns={'approx_cost(for_two_people)': 'cost_for_two', 'listed_in(type)': 'restaurant_type'}, inplace=True)\n",
    "\n",
    "# Drop unnecessary columns and initial duplicates\n",
    "df.drop(columns=['url', 'dish_liked', 'phone', 'menu_item', 'listed_in(city)', 'reviews_list'], inplace=True, errors='ignore')\n",
    "df.dropna(subset=['name'], inplace=True)\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74202133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Prepare and Clean the 'restaurants' DataFrame ---\n",
    "# This section now isolates and fully cleans the data for the restaurants table.\n",
    "restaurants_df = df[['name', 'address', 'location', 'rest_type', 'online_order', 'book_table', 'rate', 'votes', 'cost_for_two']].copy()\n",
    "restaurants_df.rename(columns={\n",
    "    'rest_type': 'restaurant_type',\n",
    "    'online_order': 'has_online_order',\n",
    "    'book_table': 'has_table_booking',\n",
    "    'rate': 'rating'\n",
    "}, inplace=True)\n",
    "\n",
    "# Clean 'rating' column\n",
    "restaurants_df['rating'] = restaurants_df['rating'].astype(str).str.replace('/5', '').str.strip()\n",
    "restaurants_df['rating'] = pd.to_numeric(restaurants_df['rating'], errors='coerce')\n",
    "\n",
    "# Clean 'cost_for_two' column\n",
    "restaurants_df['cost_for_two'] = restaurants_df['cost_for_two'].astype(str).str.replace(',', '', regex=False)\n",
    "restaurants_df['cost_for_two'] = pd.to_numeric(restaurants_df['cost_for_two'], errors='coerce')\n",
    "\n",
    "# Clean boolean columns\n",
    "restaurants_df['has_online_order'] = restaurants_df['has_online_order'].apply(lambda x: True if x == 'Yes' else False)\n",
    "restaurants_df['has_table_booking'] = restaurants_df['has_table_booking'].apply(lambda x: True if x == 'Yes' else False)\n",
    "\n",
    "# Add a temporary ID for linking later\n",
    "restaurants_df['temp_id'] = range(1, len(restaurants_df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8425bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Prepare the 'cuisines' and 'restaurant_cuisines' DataFrames ---\n",
    "df.dropna(subset=['cuisines'], inplace=True)\n",
    "\n",
    "all_cuisines = set()\n",
    "for cuisine_list in df['cuisines'].str.split(','):\n",
    "    all_cuisines.update([c.strip() for c in cuisine_list])\n",
    "\n",
    "cuisines_df = pd.DataFrame(all_cuisines, columns=['cuisine_name'])\n",
    "cuisines_df.sort_values('cuisine_name', inplace=True) # Sort for consistent IDs\n",
    "cuisines_df['cuisine_id'] = range(1, len(cuisines_df) + 1)\n",
    "\n",
    "cuisine_map = pd.Series(cuisines_df.cuisine_id.values, index=cuisines_df.cuisine_name).to_dict()\n",
    "\n",
    "# Create a temporary mapping from original df index to restaurant temp_id\n",
    "df.reset_index(inplace=True)\n",
    "temp_id_map = df[['index']].copy()\n",
    "temp_id_map['temp_id'] = range(1, len(temp_id_map) + 1)\n",
    "\n",
    "restaurant_cuisines_records = []\n",
    "for index, row in df.iterrows():\n",
    "    temp_id = temp_id_map.iloc[index]['temp_id']\n",
    "    cuisines = [c.strip() for c in row['cuisines'].split(',')]\n",
    "    for cuisine in cuisines:\n",
    "        if cuisine in cuisine_map:\n",
    "            cuisine_id = cuisine_map[cuisine]\n",
    "            restaurant_cuisines_records.append({\n",
    "                'temp_id': temp_id,\n",
    "                'cuisine_id': cuisine_id\n",
    "            })\n",
    "\n",
    "restaurant_cuisines_df = pd.DataFrame(restaurant_cuisines_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b95a1fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Clearing existing data from tables...\n",
      "‚úÖ Tables cleared.\n",
      "üöö Loading data into MySQL...\n",
      "‚úÖ 'restaurants' table populated.\n",
      "‚úÖ 'cuisines' table populated.\n",
      "‚úÖ 'restaurant_cuisines' table populated.\n",
      "\n",
      "üéâ ETL process complete! Your database is fully populated and ready for analysis.\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Clear Existing Data and Load into MySQL ---\n",
    "print(\"üóëÔ∏è Clearing existing data from tables...\")\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(\"SET FOREIGN_KEY_CHECKS = 0;\"))\n",
    "    connection.execute(text(\"TRUNCATE TABLE restaurant_cuisines;\"))\n",
    "    connection.execute(text(\"TRUNCATE TABLE cuisines;\"))\n",
    "    connection.execute(text(\"TRUNCATE TABLE restaurants;\"))\n",
    "    connection.execute(text(\"SET FOREIGN_KEY_CHECKS = 1;\"))\n",
    "    connection.commit()\n",
    "print(\"‚úÖ Tables cleared.\")\n",
    "\n",
    "print(\"üöö Loading data into MySQL...\")\n",
    "\n",
    "# Load restaurants\n",
    "restaurants_to_load = restaurants_df.drop(columns=['temp_id'])\n",
    "restaurants_to_load.to_sql('restaurants', engine, if_exists='append', index=False, chunksize=500)\n",
    "print(\"‚úÖ 'restaurants' table populated.\")\n",
    "\n",
    "# Load cuisines\n",
    "cuisines_to_load = cuisines_df[['cuisine_name']] # Only load the name, ID is auto-incremented\n",
    "cuisines_to_load.to_sql('cuisines', engine, if_exists='append', index=False)\n",
    "print(\"‚úÖ 'cuisines' table populated.\")\n",
    "\n",
    "# Get the real, auto-generated IDs back from the database\n",
    "db_restaurants = pd.read_sql(\"SELECT restaurant_id, name, location FROM restaurants\", engine)\n",
    "db_cuisines = pd.read_sql(\"SELECT cuisine_id, cuisine_name FROM cuisines\", engine)\n",
    "\n",
    "# Merge to get the real IDs\n",
    "restaurants_with_real_ids = restaurants_df.merge(db_restaurants, on=['name', 'location'], how='left')\n",
    "cuisines_df = cuisines_df.merge(db_cuisines, on='cuisine_name', how='left')\n",
    "\n",
    "# Prepare the final linking table with the real restaurant_id and cuisine_id\n",
    "final_linking_df = restaurant_cuisines_df.merge(restaurants_with_real_ids[['temp_id', 'restaurant_id']], on='temp_id')\n",
    "final_linking_df = final_linking_df.merge(cuisines_df[['cuisine_id_x', 'cuisine_id_y']].rename(columns={'cuisine_id_x':'cuisine_id', 'cuisine_id_y':'real_cuisine_id'}), on='cuisine_id')\n",
    "final_linking_df = final_linking_df[['restaurant_id', 'real_cuisine_id']].rename(columns={'real_cuisine_id':'cuisine_id'})\n",
    "final_linking_df.dropna(inplace=True)\n",
    "final_linking_df.drop_duplicates(inplace=True)\n",
    "final_linking_df['restaurant_id'] = final_linking_df['restaurant_id'].astype(int)\n",
    "final_linking_df['cuisine_id'] = final_linking_df['cuisine_id'].astype(int)\n",
    "\n",
    "# Load the linking table\n",
    "final_linking_df.to_sql('restaurant_cuisines', engine, if_exists='append', index=False, chunksize=1000)\n",
    "print(\"‚úÖ 'restaurant_cuisines' table populated.\")\n",
    "\n",
    "print(\"\\nüéâ ETL process complete! Your database is fully populated and ready for analysis.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
